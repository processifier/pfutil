#!/usr/bin/env python
import logging
import os
import pandas as pd

from pfr import LogProcessor
from pfr.cmdline import Parser
from pfr.config import load_config, LOGGING_FORMAT

DEFAULT_OUTPUT_DIR = 'processifier_output'
DEFAULT_TIMESTAMP_MASK = "%Y-%m-%dT%H:%M:%S"
DEFAULT_PROCESS_NAME = "process"
DEFAULT_EVENTLOG_COLUMNS = {
    "caseId": "case_id",
    "activity": "activity",
    "endTimestamp": "end_time",
    "startTimestamp": "start_time",
    "resource": "resource"
}

DEFAULT_INPUT_CONFIG = {'input': {'timestampMask': DEFAULT_TIMESTAMP_MASK,
                                  'processName': DEFAULT_PROCESS_NAME,
                                  'eventlogInputColumns': DEFAULT_EVENTLOG_COLUMNS}}

logging.basicConfig(format=LOGGING_FORMAT)
LOG = logging.getLogger()
LOG.setLevel(logging.INFO)

cmd_parser = Parser()
cmd_args = cmd_parser.args()

if cmd_args.config:
    LOG.debug("Using config: %s", cmd_args.config)
    config, params = load_config(cmd_args)
else:
    config = DEFAULT_INPUT_CONFIG
    params = cmd_args
    print("No config file specified")
    print("Applying default configuration:")
    print(f" Timestamp mask: {DEFAULT_TIMESTAMP_MASK}")
    print(f" Process name: {DEFAULT_PROCESS_NAME}")
    print(" Eventlog columns:")
    print(f"\t caseId (Case ID) -> {DEFAULT_EVENTLOG_COLUMNS.get('caseId')}")
    print(f"\t activity (Activity) -> {DEFAULT_EVENTLOG_COLUMNS.get('activity')}")
    print(f"\t startTimestamp (Start timestamp) -> {DEFAULT_EVENTLOG_COLUMNS.get('startTimestamp')}")
    print(f"\t endTimestamp (End timestamp) -> {DEFAULT_EVENTLOG_COLUMNS.get('endTimestamp')}")
    print(f"\t resource (Resource) -> {DEFAULT_EVENTLOG_COLUMNS.get('resource')}")

def create_model(input_config, eventlog):
    lp = LogProcessor(input_config)
    return lp.create_model(eventlog)


def save_to_csv(model, output_path):
    LOG.info(f"Saving model:")
    for t, df in model.items():
        file_name = os.path.join(output_path, f'{t.__tablename__}.csv')
        df.to_csv(file_name, index=False)
        LOG.info(f"\t{file_name}")
    LOG.info("Saving model...OK")


if cmd_args.command == Parser.COMMAND_PUT:
    LOG.info("Loading eventlog: %s", params.eventlog)
    eventlog = pd.read_csv(params.eventlog)
    LOG.debug("Loading eventlog: %s ... OK", params.eventlog)

    LOG.info(f"Creating model...")
    model = create_model(config['input'], eventlog)
    LOG.info(f"Creating model...OK")
    output_path = params.csv_out if params.csv_out else DEFAULT_OUTPUT_DIR
    if not params.csv_out:
        print("No output dir specified")
        print(f"\t Output files will be saved to: {os.path.join(os.getcwd(), output_path)} ")
    try:
        os.makedirs(output_path, exist_ok=params.force_overwrite)
    except FileExistsError:
        print("Output dir already exists, use --force-overwrite to overwrite.")
        exit(1)
    save_to_csv(model, output_path=output_path)
